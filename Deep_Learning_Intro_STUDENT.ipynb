{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Intro - STUDENT",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcharzat/collab/blob/main/Deep_Learning_Intro_STUDENT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UwCWf6IhOt9"
      },
      "source": [
        "# Classification of Satellite Superspectral Images\n",
        "\n",
        "In this exercise, we will implement two deep learning approaches for classifying images of agricultural parcels from Sentinel2 multispectral images. \n",
        "We will implement a **Multi-Layer Perceptron** and a **Convolutional Classifier**.\n",
        "\n",
        "$\\qquad\\qquad\\qquad\\qquad$<img src=\"https://drive.google.com/uc?id=1sNyYsrExnr6j1YyprhpyllRzgMeepJVU\" alt=\"Teaser\"  width=\"500\"/>\n",
        "\n",
        "The data considered is composed of $10\\,000$ agricultural parcels for the training test and $5000$ parcels for the test set. Each parcel is a $10\\times32\\times32$ image of resolution $32\\times 32$ with $10$ spectral bands, captured with the Senintel-2 optical satellite.\n",
        "\n",
        "The selected parcels follow a nomenclature of $8$ agricultural classes:\n",
        "\n",
        "> **Class Index** | **Class Name** \n",
        "> --- | --- \n",
        "> 0  | Meadow\n",
        "> 1  | Durum Wheat \n",
        "> 2  | Spring Cereal\n",
        "> 3  | Sorgho\n",
        "> 4  | Leguminous\n",
        "> 5  | Fodder\n",
        "> 6  | Ligneous\n",
        "> 7  | Grapevine\n",
        "\n",
        "\n",
        "\n",
        "Throughout this exercise, we will implement a full deep learning pipeline brick by brick. The structure of the code is already implemented, you will have to complete some of the code denoted by the following flag: ```#TODO```\n",
        "\n",
        "I have added some assertions in the code `assert` to check your code. only go to the next question if the assert passes succesfuly.\n",
        "\n",
        "Since this is a notebook, it can be a bit cumbersome to debug. Do not hesitate to create extra cell and visualize the content of the tensors. Alternatively, I encourage you to add `print` to visualize the shape and content of tensors.\n",
        "\n",
        "\n",
        "**Grading**: When you are done this exercise, send me a shareable link to your collab from your Google Drive: in `My drive -> Colab Notebooks`, right click on your file, chose `get shareable link`, activate link sharing and copy/paste the link in an email to me.\n",
        "The grade itself has three components:\n",
        "* completing the code (30%): complete all the ```#TODO``` up to Q12.\n",
        "* answer the questions (20%): Answer in your notebook to the  <font color='red'>questions in red</font>. Answers should be short (1 or 2 sentences max).\n",
        "* Extra points: Q13+ are less guided and will require a little bit more initiatives. Each question has a difficuty rating from easy $\\star$ to difficult $\\star\\star\\star$. Complete as many as you can.\n",
        "\n",
        "## Preliminaries\n",
        "\n",
        "First do `Select File→Save a copy in Drive`. Then select `Runtime→Change runtime type` and select `GPU`.\n",
        "\n",
        "Let's first start by importing and installing the necessary libraires:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3toeVsmfxPn1"
      },
      "source": [
        "#install on the VM libraries that are not installed by default\n",
        "!pip install torchnet\n",
        "!pip install PyDrive\n",
        "!pip install mock\n",
        "#general purpose libraires\n",
        "import math\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import mock\n",
        "#format libraries\n",
        "import h5py\n",
        "#visualization libraries\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "#machine learning tools\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#deep learning tools\n",
        "import torch\n",
        "import torchnet as tnt\n",
        "import torch.nn.functional as nnf\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm.auto import tqdm\n",
        "#collab specific libraries\n",
        "from google.colab import files\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km8zZu-xhYBL"
      },
      "source": [
        "Let's now download the data. To do this, you must first connect to your Google account to get the authorization to link to my drive. Launch the next cell, click the link, select your account, and click `authorize`. Copy and paste the verification code in the box below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4Zo83G_yXl3"
      },
      "source": [
        "#Authentification\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "downloaded = drive.CreateFile({'id':'1owyqy_JKqMF0dhOwroM3J0siZsfRYthk'})\n",
        "downloaded.GetContentFile('crop_data.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdTiEMQhzqOw"
      },
      "source": [
        "The dataset is comprised of $10\\,000$ patches of $10 \\times 32\\times 32$ for for training, and $5000$ for testing. The parcels only occupy part of the image, the rest of the images have been padded with zero representing the `nodata` vbalue.\n",
        "\n",
        "Launch the next cell to read the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA3TzAtJ0DgN"
      },
      "source": [
        "#Data loading\n",
        "data_file = h5py.File(\"crop_data.h5\",'r')\n",
        "data_train_raw = data_file['train_data'][:]\n",
        "labels_train = data_file['train_labels'][:]\n",
        "data_test_raw = data_file['test_data'][:]\n",
        "labels_test = data_file['test_labels'][:]\n",
        "\n",
        "n_train = data_train_raw.shape[0]\n",
        "n_test = data_test_raw.shape[0]\n",
        "class_names = [\"Meadow\", \"Durum Wheat\", \"Spring Cereal\", \"Sorgho\", \"Leguminous\", \"Fodder\", \"Ligneous\", \"Grapevine\"]\n",
        "\n",
        "print(\"%d tiles for training, %d tiles for testing\" % (n_train, n_test))\n",
        "print(\"Train is of size: %d x %d x %d x %d\" % (data_train_raw.shape))\n",
        "freq = plt.hist(labels_train, bins=8, range=(0,8))\n",
        "plt.xticks(ticks=[0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5], labels=class_names, rotation='vertical')\n",
        "plt.title(\"class repartition in training set\")\n",
        "print('\\n'.join('{:13s} : {:4.0f} samples'.format(name, freq[0][i]) for i, name in enumerate(class_names)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INhKP7uchYIc"
      },
      "source": [
        "## Data Normalization\n",
        "\n",
        "Q1) In machine learning in general, and deep learning in particular, it is important for the data to be normalized. Complete the next cell to normalize the train set such that all channels to be of mean $0$ and deviation $1$ over all pixels of all images. Apply the same normalization to the test set, **with the empirical values obtained from the training set.** \n",
        "\n",
        "<font color='red'>Why is it important to normalize the test set with the empirical values obtained from the training set and not the test set?</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaQ-vI6QP-v6"
      },
      "source": [
        "#compute mean and std values for normalizing\n",
        "#we keep the original dimension to facilitate broadcasting\n",
        "means = np.mean(data_train_raw,axis=(0,2,3), keepdims=True)\n",
        "stds = np.std(data_train_raw, axis=(0,2,3), keepdims=True)\n",
        "print(\"Means = \")\n",
        "print(means[0,:,0,0])\n",
        "print(\"STDs = \")\n",
        "print(stds[0,:,0,0])\n",
        "\n",
        "#normalize raw data to be of mean 0 and std 1\n",
        "data_train = #TODO\n",
        "data_test = #TODO\n",
        "\n",
        "#check that the code is correct\n",
        "assert(np.all([np.abs(np.mean(data_train[:,i]))<1e-4 for i in range(10)]))\n",
        "assert(np.all([np.abs(np.std(data_train[:,i])-1)<1e-4 for i in range(10)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ilvh6ZHJQJth"
      },
      "source": [
        "\n",
        "## Data Loader\n",
        "\n",
        "Any deep learning pipeline rely on a dataloader, which loads a single element (here a patch). Read and understand the function.\n",
        "Complete the function to compute the patch-wise spatial average  if `average=True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTytQAd30g_b"
      },
      "source": [
        "def patch_loader(patch_index, train=True, average=False):\n",
        "  \"\"\"\n",
        "  load a patch and returns the observation and associated ground truth\n",
        "  INPUT:\n",
        "  tile_index = int, index of the tile\n",
        "  train = bool, train = True if in the train set, False for the test set\n",
        "  average = if True, compute the spatial average of spectral bands, otherwise returns an image\n",
        "  OUTPUT\n",
        "  patch, if average=True [10] float tensor, otherwise [10 x 32 x 32]  float tensor \n",
        "  label, long int, containing the ground truth class \n",
        "  \"\"\"\n",
        "  if train:\n",
        "    patch = data_train[patch_index,:,:,:]\n",
        "    label = labels_train[patch_index]\n",
        "  else:\n",
        "    patch = data_test[patch_index,:,:,:]\n",
        "    label = labels_test[patch_index]\n",
        "\n",
        "  if average:#spatial average on all pixels of the parcel:\n",
        "    patch = #TODO\n",
        "\n",
        "  #create torch tensors\n",
        "  patch = torch.from_numpy(patch.astype('f4')) #use float to save space\n",
        "  label = torch.Tensor([label]).long()  #ground truth must have long int type    \n",
        "   \n",
        "  return patch, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqILuI9kUNrj"
      },
      "source": [
        "patch, label = patch_loader(500)\n",
        "print(\"The image patch is of shape : %d x %d x %d\" % (patch.shape))\n",
        "print(\"and its label is %s\" % (class_names[label]))\n",
        "patch, label = patch_loader(200, average=True)\n",
        "print(\"The average patch is of shape : %d\" % (patch.shape))\n",
        "print(\"and its label is %s\" % (class_names[label]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oy4Q9lkhYMa"
      },
      "source": [
        "## Data Visualization\n",
        "\n",
        "Writing some visualization functions to explore the data and the results is very important.\n",
        "Read and understand the definition of `view_patch_RGB` and `show_random_patches`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0D7srfjR59f"
      },
      "source": [
        "#functions used for visualization\n",
        "def view_patch_RGB(patch, ax):\n",
        "  \"\"\"\n",
        "  INPUT: \n",
        "  patch - CxWxH array: the patch to visualize\n",
        "  ax - subplot axis: in which windows to represent the patch\n",
        "  \"\"\"\n",
        "  patch = np.swapaxes(patch[[2,1,0],:,:],0,-1)\n",
        "  patch = np.minimum(1,np.maximum(0,(patch+2)/4))\n",
        "  ax.imshow(patch)\n",
        "  plt.axis('off')\n",
        "    \n",
        "def show_random_patches(num_patches, train = True):\n",
        "  \"\"\" show random patches values\n",
        "  INPUT: \n",
        "  num_patches - int: the number of patches to show\n",
        "  train - bool: if true loads from the train set, otherwise the test set\n",
        "  \"\"\"\n",
        "  n_row = int(num_patches / 4 + 1) #4 columns\n",
        "  fig = plt.figure(figsize=(10, n_row * 2.5))\n",
        "  for i_image in range(num_patches):\n",
        "    index = np.random.randint(n_train) if train else np.random.randint(n_test)\n",
        "    patch, label = patch_loader(index, train = train)\n",
        "    ax = fig.add_subplot(n_row, 4, i_image+1, aspect='equal')\n",
        "    view_patch_RGB(patch, ax)  \n",
        "    ax.set_title(class_names[label])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oySJufY6JUrb"
      },
      "source": [
        "Q2) Use the function `show_random_patches` to represent 16 random tiles of the\n",
        "**test set**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7iyfh-NR5_u"
      },
      "source": [
        "show_random_patches(#TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vPPhByXKEwb"
      },
      "source": [
        "## Multi-Layer perceptron\n",
        "\n",
        "We start by implementing a simple MLP operating on the spatial average of each parcel's spectral channels. This networks maps the vector of size $10$ of the spectral average to a vector of $8$ class scores corresponding to the crop classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZO1i5CmyBJa"
      },
      "source": [
        "\n",
        "We now define the architecture of our MLP.\n",
        "\n",
        "The input layer is of size $C$ (the number of bands, here 10) and the last layer is of size $K$ (the number of classes , here $8$). We add $2$ intermediate representations $x_1$ and $x_2$ of size $d_1$ and $d_2$.\n",
        "\n",
        "Between each representation we add a fully connected layer FC. After each fully connected except the last one, we add a batchnorm and a ReLU activation.\n",
        " \n",
        "The equations describing the function defined by the MLP are as follows:\n",
        "$$\\newcommand{\\FC}[2]{\\text{FC}_{#1}\\left(#2\\right)}$$\n",
        "$$\\newcommand{\\BN}[1]{\\text{BatchNorm}\\left(#1\\right)}$$\n",
        "$$\\newcommand{\\RELU}[1]{\\text{ReLU}\\left(#1\\right)}$$\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1qGul7aryVktkb8wm6pEdOHmTnltp5sU5\" alt=\"mlp\"  width=\"500\"/>\n",
        "\n",
        "\\begin{align}\n",
        "x_1  &= \\RELU{\\BN{\\FC{1}{\\text{input}}}}\\\\\n",
        "x_2  &= \\RELU{\\BN{\\FC{2}{x_1}}}\\\\\n",
        "\\text{output}  &= \\FC{3}{x_2}\\\\\n",
        "\\end{align}\n",
        "\n",
        "The size of all tensors is given in the following Table:\n",
        "\n",
        "> **Tensor**           |    **shape**   |\n",
        "> -------------------- | -------------------------------------------------|\n",
        "> input                |  $C$                           |\n",
        "> $x_1$                |  $d_1$                         | \n",
        "> $x_2$                |  $d_2$                         | \n",
        "> output               |  K\n",
        "\n",
        "Q3 Complete the following cell to create the layer and implement the forward function. <font color='red'>Give the formula for the number of parameters (weights) in  $\\text{FC}_1$ (don't forget the biases).</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nzzn3K0vRAr"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  \"\"\"\n",
        "  MLP network for classification\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, n_channels, hidden_width,  n_class, cuda=1):\n",
        "    \"\"\"\n",
        "    initialization function\n",
        "    n_channels, int, number of input channel\n",
        "    hidden_width, int list, width of hidden layers\n",
        "    n_class = int,  the number of classes\n",
        "    \"\"\"\n",
        "    super(MLP, self).__init__() #necessary for all classes extending the module class\n",
        "\n",
        "    self.is_cuda = cuda\n",
        "    \n",
        "    self.fc1 = nn.Sequential( \\\n",
        "        nn.Linear(in_features=n_channels, out_features=hidden_width[0]), \\\n",
        "        nn.BatchNorm1d(num_features=hidden_width[0]), \\\n",
        "        nn.ReLU(True))\n",
        "    self.fc2 = nn.Sequential( \\\n",
        "        nn.Linear( in_features=#TODO,out_features=#TODO), \\\n",
        "        nn.BatchNorm1d(num_features=#TODO), \\\n",
        "        nn.ReLU(True))\n",
        "    self.fc3 = nn.Linear(in_features=#TODO,out_features=#TODO)\n",
        "    #no activation and norm after last layer!\n",
        "    \n",
        "    if cuda: #put the model on the GPU memory\n",
        "      self.cuda()\n",
        "    \n",
        "  def forward(self,input):\n",
        "    \"\"\"\n",
        "    the foward pass : maps input to output\n",
        "    \"\"\" \n",
        "    if self.is_cuda: #input to the GPU at the last second to save some VRAM\n",
        "      input = input.cuda()\n",
        "\n",
        "    x1 = self.fc1(input)\n",
        "    x2 = #TODO\n",
        "    output = #TODO\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V282Hczb2O_X"
      },
      "source": [
        "#==================TEST===============================\n",
        "#make a batch of 2 patches\n",
        "patch1, label = patch_loader(0, average=True)\n",
        "patch2, label = patch_loader(1, average=True)\n",
        "patches = torch.cat((patch1[None,:],patch2[None,:]),0)\n",
        "#create classifier\n",
        "mlp = MLP(10,[128,128],8)\n",
        "#print layers + number of parameters\n",
        "print(mlp)\n",
        "print('Total number of parameters: {}'.format(sum([p.numel() for p in mlp.parameters()])))\n",
        "#classify batch\n",
        "pred = mlp(patches)\n",
        "#check the shape of the outcome\n",
        "assert(pred.shape == torch.Size([2,8]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3k5Gk1aWM3Y"
      },
      "source": [
        "\n",
        "## Evaluation Metrics\n",
        "\n",
        "Q5 Complete the metric functions belows, defined with respect to the confusion matrix $M$ of size $K \\times K$:\n",
        "\n",
        "* *Overall Accuracy*: a global metric defined as the ratio of correct prediction divided by the number of (annotated) points\n",
        "    $$\n",
        "    OA = \\frac{\\sum_{i}M_{i,i}}\n",
        "    {\\sum_{i,j}M_{i,j}}~.\n",
        "    $$\n",
        "* *Class IoU*: this per-class metric is defined as the ratio between true positives divided by the sum of false positives, false negatives and true positives.\n",
        "    $$\n",
        "    IoU_i = \\frac{M_{i,i}}\n",
        "    {M_{i,i} + \\sum_{j \\neq i}\\left(M_{i,j} + M_{j,i} \\right)}\n",
        "    ~.\n",
        "    $$\n",
        "We typically compute the per-class averagr IoU to evaluate a classification method.\n",
        "\n",
        "Make sure you obtain the following:\n",
        "```\n",
        "OA = 76,00%\n",
        "Meadow        : 71.43%\n",
        "Durum Wheat   : 57.14%\n",
        "Spring Cereal : 100.00%\n",
        "Sorgho        : 100.00%\n",
        "Leguminous    : 100.00%\n",
        "Fodder        : 66.67%\n",
        "Ligneous      : 25.00%\n",
        "Grapevine     : 25.00%\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17Ohx9RVh6Ze"
      },
      "source": [
        "class ConfusionMatrix:\n",
        "  def __init__(self, n_class, class_names):\n",
        "    self.CM = np.zeros((n_class, n_class)) #the matrix itself\n",
        "    self.n_class = n_class\n",
        "    self.class_names = class_names\n",
        "    \n",
        "  def add_batch(self, gt, pred):\n",
        "    #add in the CM a batch of prediction and associated ground truth\n",
        "    self.CM +=  confusion_matrix(gt, pred, labels = list(range(self.n_class)))\n",
        "    \n",
        "  def overall_accuracy(self):#percentage of correct classification\n",
        "    return #TODO - hint: use np.trace and np.sum\n",
        "\n",
        "  def class_IoU(self, show = 0):#IoU for each class\n",
        "    ious = #TODO- hint: use np.diag and np.sum\n",
        "\n",
        "    if show: #print detailed values\n",
        "      print('\\n'.join('{:13s} : {:3.2f}%'.format(name, 100*iou) for name, iou in zip(self.class_names,ious)))\n",
        "    #do not count classes that are not present in the dataset in the mean IoU\n",
        "    return 100*np.nansum(ious) / (np.logical_not(np.isnan(ious))).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJPZG2yyh7VG"
      },
      "source": [
        "m = ConfusionMatrix(8, class_names)\n",
        "m.add_batch(np.array([0,1,1,5,2,0,0,4,0,5,3,7,8,6,7]), np.array([0,1,0,5,2,0,1,4,0,5,3,6,7,6,7]))\n",
        "m.add_batch(np.array([0,1,5,1,2,1,0,2,3,6,7]), np.array([0,1,1,1,2,1,0,2,3,7,6]))\n",
        "print(m.CM)\n",
        "print(\"OA = %3.2f%%\" % (100*m.overall_accuracy()))\n",
        "print(\"mIoU = %3.2f%%\" % (m.class_IoU(show=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab5nm4CHX1mU"
      },
      "source": [
        "Q6) Read in the `train` function following cell. Complete the function `eval`  which performs inference with the trained model. This function computes a prediction and the loss but does not compute gradients nor make an optimizer step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIOWMc9PR6BT"
      },
      "source": [
        "def train(model, optimizer, loader, args):\n",
        "  \"\"\"train for one epoch\n",
        "  INPUT:\n",
        "  model = current model\n",
        "  optimizer = current optimizer\n",
        "  loader = dataset constituting the epoch\n",
        "  args = otptions\n",
        "  OUTPUT:\n",
        "  cm = the confusion matrix over the entire epoch\n",
        "  lm = the average loss\n",
        "  \"\"\"\n",
        "  model.train() #switch the model in training mode\n",
        "  \n",
        "  #tqdm will provide some nice progress bars\n",
        "  loader = tqdm(loader, ncols=500, leave=False, desc=\"Train Epoch\")\n",
        "  \n",
        "  #will keep track of the loss\n",
        "  loss_meter = tnt.meter.AverageValueMeter()\n",
        "  #keep tracks of prediction errors\n",
        "  cm = ConfusionMatrix(args.n_class, class_names = class_names)\n",
        "\n",
        "  #goes through the entire dataset\n",
        "  for index, (tiles, label) in enumerate(loader):\n",
        "\n",
        "    if model.is_cuda: #put label on GPU\n",
        "      label = label.cuda()\n",
        "  \n",
        "    optimizer.zero_grad() #put gradient to zero\n",
        "    \n",
        "    pred = model(tiles) #compute the prediction\n",
        "\n",
        "    loss = nn.functional.cross_entropy(pred,label.squeeze()) #compute the loss\n",
        "\n",
        "    loss.backward() #compute gradients\n",
        "   \n",
        "    optimizer.step() #one gradient descent step\n",
        "    \n",
        "    #add the loss to the meter\n",
        "    loss_meter.add(loss.item()) \n",
        "    #fill the confusion matrix\n",
        "    cm.add_batch(label.cpu().detach().numpy(), pred.argmax(1).view(-1).cpu().detach().numpy())\n",
        "    \n",
        "  return cm, loss_meter.value()[0]\n",
        "\n",
        "def eval(model, loader, args):\n",
        "  \"\"\"\n",
        "  classify the given dataset. DO NOT track gradients\n",
        "  INPUT:\n",
        "  model = model to evaluate\n",
        "  loader = dataset to classify\n",
        "  OUTPUT:\n",
        "  cm = the confusion matrix over the entire dataset\n",
        "  lm = the average loss\n",
        "  \"\"\"\n",
        "  \n",
        "  model.eval() #switch in eval mode\n",
        "  \n",
        "  loader = tqdm(loader, ncols=500, leave=False, desc=\"Validation\")\n",
        "  \n",
        "  loss_meter = tnt.meter.AverageValueMeter()\n",
        "  cm = ConfusionMatrix(args.n_class, class_names = class_names)\n",
        "\n",
        "  with torch.no_grad(): #do not compute gradients (saves memory)\n",
        "    for index, (tiles, label) in enumerate(loader):\n",
        "\n",
        "     #TODO\n",
        "      \n",
        "  return cm, loss_meter.value()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6C9uxRT62Cu"
      },
      "source": [
        "The following cell is the entire training sequence. Read and understand the structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83VbFJ7DM4Hk"
      },
      "source": [
        "def train_full(model, args):\n",
        "  \"\"\"The full training loop\"\"\"\n",
        "  \n",
        "  #create train and test dataset with ListDataset (as list of patch index)\n",
        "  train_set_average = tnt.dataset.ListDataset(\n",
        "    list(range(n_train)),partial(patch_loader, train=True, average=args.average))\n",
        "  test_set_average  = tnt.dataset.ListDataset(\n",
        "    list(range(n_test)), partial(patch_loader, train=False, average=args.average))\n",
        "  \n",
        "  #the loader function will take care of the batching\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_set_average, batch_size=args.batch_size, shuffle=True,\n",
        "      drop_last=True)\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "      test_set_average, batch_size=args.batch_size, shuffle=False,\n",
        "      drop_last=False)\n",
        "\n",
        "  #define the optimizer\n",
        "  #Adam optimizer is always a good guess for classification tasks\n",
        "  optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "  \n",
        "  #defines some color for test and train texts\n",
        "  TESTCOLOR = '\\033[104m'\n",
        "  TRAINCOLOR = '\\033[100m'\n",
        "  NORMALCOLOR = '\\033[0m'\n",
        "  \n",
        "  for i_epoch in tqdm(range(args.n_epoch), desc=\"Training\"):\n",
        "    #train one epoch\n",
        "    cm_train, loss_train = train(model, optimizer, train_loader, args)\n",
        "    tqdm.write(TRAINCOLOR + 'Epoch %3d -> Train Overall Accuracy: %3.2f%% Train mIoU : %3.2f%% Train Loss: %1.4f' % (i_epoch, 100*cm_train.overall_accuracy(), cm_train.class_IoU(), loss_train) + NORMALCOLOR)\n",
        "\n",
        "    #periodic testing\n",
        "    if (i_epoch == args.n_epoch - 1) or (args.n_epoch_test != 0 and i_epoch % args.n_epoch_test == 0 and i_epoch > 0):\n",
        "      #evalue performance over the test set\n",
        "      cm_test, loss_test = eval(model, test_loader, args)\n",
        "      tqdm.write(TESTCOLOR + 'Test Overall Accuracy: %3.2f%% Test mIoU : %3.2f%%  Test Loss: %1.4f' % (100*cm_test.overall_accuracy(), cm_test.class_IoU(show=1), loss_test) + NORMALCOLOR)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AJ0FPv3YIgs"
      },
      "source": [
        "Q7) Create and train a model with the following parameter in the following cell. You should reach a mIoU of $\\sim$ 40\\%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5D1_H5pR6DL"
      },
      "source": [
        "args = mock.Mock() #stores the parameters\n",
        "args.n_epoch = 50 #number of epochs\n",
        "args.n_epoch_test = int(5) #periodicity of evaluation on test set\n",
        "args.batch_size = 16 #size of batch\n",
        "args.n_class = 8 #number of classes\n",
        "args.n_channel = 10 #number of channels\n",
        "args.cuda = 1 #wether to use the GPU\n",
        "args.lr = 5e-3 #learning rate\n",
        "args.hidden_width = [256,256] #size of hidden layers\n",
        "args.average = True #compute spatial average of each patch\n",
        "\n",
        "#create the model to train\n",
        "model = MLP(#TODO\n",
        "print('Total number of parameters: {}'.format(sum([p.numel() for p in model.parameters()])))\n",
        "\n",
        "#train the model\n",
        "trained_model = train_full(#TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDgRS3unYVWQ"
      },
      "source": [
        "## Convolutional Classifier\n",
        "\n",
        "$$\\newcommand{\\Conv}[2]{\\text{Conv}_{#1}\\left(#2\\right)}$$\n",
        "$$\\newcommand{\\FC}[2]{\\text{FC}_{#1}\\left(#2\\right)}$$\n",
        "$$\\newcommand{\\BN}[1]{\\text{BatchNorm}\\left(#1\\right)}$$\n",
        "$$\\newcommand{\\RELU}[1]{\\text{ReLU}\\left(#1\\right)}$$\n",
        "$$\\newcommand{\\MAX}[1]{\\text{Maxpool}\\left(#1\\right)}$$\n",
        "$$\\newcommand{\\MEAN}[1]{\\text{Mean}\\left(#1\\right)}$$\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1l7e2nYV_dKCGvUopmgw8MxzVINCvtZvO\" alt=\"CNN\"  width=\"500\"/>\n",
        "\n",
        "We will now define a CNN network, more appropriate for image classification.\n",
        "\n",
        "The input is an image of size $C\\times W\\times H$ with C the number of bands (here 10) and W and H the width and height (here 32). The output is a vector of size $K$ (the number of classes , here $8$).\n",
        "\n",
        "The CNN is composed of a sequence of convolutions to extract local radiometric features and maxpooling operations to reduce the size of the feature map. Then the learned features are averaged spatially to obtain a vector of aggregated feature. Finally, a fully connected layer maps this vector to the class vector. All convolutions have a $3\\times3$ kernel.\n",
        " \n",
        "The equations describing the function defined by the CNN are as follows:\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "x_1  &= \\RELU{\\BN{\\Conv{1}{\\text{input}}}}\\\\\n",
        "x_2  &= \\RELU{\\BN{\\Conv{2}{x_1}}}\\\\\n",
        "x_3  &= \\MAX{x_2}\\\\\n",
        "x_4  &= \\RELU{\\BN{\\Conv{3}{x_3}}}\\\\\n",
        "x_5  &= \\RELU{\\BN{\\Conv{4}{x_4}}}\\\\\n",
        "x_6  &= \\MEAN{x_5}\\\\\n",
        "\\text{output}  &= \\FC{1}{x6}\\\\\n",
        "\\end{align}\n",
        "\n",
        "The size of all tensors is given in the following Table:\n",
        "\n",
        "> **Tensor**           |    **&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Shape of Vectors&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**                          |\n",
        "> -------------------- | --------------------------------------|      \n",
        "> input                |  $C\\times W \\times H$                           |\n",
        "> $x_1$                |  $d_1\\times W \\times H$                         | \n",
        "> $x_2$                |  $d_2\\times W \\times H$                         | \n",
        "> $x_3$                |  $d_2\\times \\lceil{{W}/{2}}\\rceil \\times \\lceil{{H}/{2}}\\rceil$    | \n",
        "> $x_4$                |  $d_3\\times \\lceil{{W}/{2}}\\rceil \\times \\lceil{{H}/{2}}\\rceil$                         | \n",
        "> $x_5$                |  $d_4\\times \\lceil{{W}/{2}}\\rceil \\times \\lceil{{H}/{2}}\\rceil$                         | \n",
        "> $x_6$                |  $d_4$|\n",
        "> output               |  $K$\n",
        "\n",
        "\n",
        "Q8) Complete the following cell to define the convolutional classsifier. Make sure that the assert passes.\n",
        "\n",
        "<font color='red'>Give the formula for the number of parameters (weights) in  $\\text{Conv2}$ (don't forget the biases).</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWiLoVYR06t0"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  \"\"\"\n",
        "  CNN network for image classification\n",
        "  \"\"\"  \n",
        "  def __init__(self, n_channels, conv_width,  n_class, cuda = 1):\n",
        "    \"\"\"\n",
        "    initialization function\n",
        "    n_channels, int, number of input channel\n",
        "    conv_width, int list, width of hidden convolutional layers\n",
        "    n_class = int,  the number of classes\n",
        "    \"\"\"\n",
        "    super(CNN, self).__init__() #necessary for all classes extending the module class\n",
        "    self.is_cuda = cuda\n",
        "    self.class_weight = None #cf Q13 torch.tensor([5., 0.5, 1, 1, 1,1, 0.5 , 1])\n",
        "    self.maxpool = nn.MaxPool2d(2,2) #maxpooling layer\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=n_channels, out_channels=conv_width[0] , kernel_size=3, padding=1, padding_mode='reflect'), \\\n",
        "        nn.BatchNorm2d(num_features=conv_width[0]), \\\n",
        "        nn.ReLU(True))\n",
        "    self.conv2 = nn.Sequential( \\\n",
        "        nn.Conv2d(in_channels=#TODO, out_channels#TODO , kernel_size=3, padding=1, padding_mode='reflect'), \\\n",
        "        nn.BatchNorm2d(num_features=#TODO), \\\n",
        "        nn.ReLU(True))\n",
        "    self.conv3 = nn.Sequential( \\\n",
        "        nn.Conv2d(in_channels=#TODO, out_channels=#TODO , kernel_size=3, padding=1, padding_mode='reflect'), \\\n",
        "        nn.BatchNorm2d(num_features=#TODO), \\\n",
        "        nn.ReLU(True))\n",
        "    self.conv4 = nn.Sequential( \\\n",
        "        nn.Conv2d(in_channels=#TODO, out_channels=#TODO , kernel_size=3, padding=1, padding_mode='reflect'), \\\n",
        "        nn.BatchNorm2d(num_features=#TODO), \\\n",
        "        nn.ReLU(True))\n",
        "\n",
        "    self.fc = nn.Linear(in_features=#TODO,out_features=n_class)\n",
        "    \n",
        "    if cuda: #put the model on the GPU memory\n",
        "      self.cuda()\n",
        "    \n",
        "  def forward(self,input):\n",
        "    \"\"\"\n",
        "    the foward pass : maps input to output\n",
        "    \"\"\"  \n",
        "    if self.is_cuda:\n",
        "      input = input.cuda()\n",
        "\n",
        "    x1 = #TODO\n",
        "    x2 = #TODO\n",
        "    x3 = self.maxpool(x2)\n",
        "    x4 = #TODO\n",
        "    x5 = #TODO\n",
        "    x6 = x5.mean(dim=(2,3))\n",
        "    output = #TODO\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDjdnz9Ictfw"
      },
      "source": [
        "#==================TEST===============================\n",
        "#load a batch of 2 patches\n",
        "patch1, label = patch_loader(0)\n",
        "patch2, label = patch_loader(1)\n",
        "patches = torch.cat((patch1[None,:,:,:],patch2[None,:,:,:]),0)\n",
        "cnn = CNN(10,[16,32,64,64],8)\n",
        "print(cnn)\n",
        "print('Total number of parameters: {}'.format(sum([p.numel() for p in cnn.parameters()])))\n",
        "pred = cnn(patches)\n",
        "assert(pred.shape == torch.Size([2,8]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9qmTxbXMqWz"
      },
      "source": [
        "Q9) Complete the following cell, defining the learning procedure for the CNN.  You should reach a mIoU of $\\sim$ 60\\%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wT_46v0aExf"
      },
      "source": [
        "#[12]\n",
        "args = mock.Mock() #stores the parameters\n",
        "args.n_epoch = 50\n",
        "args.n_epoch_test = int(5)\n",
        "args.batch_size = 16\n",
        "args.n_class = 8\n",
        "args.n_channel = 10\n",
        "args.conv_width = [16,64,64,64]\n",
        "args.cuda = 1\n",
        "args.lr = 5e-3\n",
        "args.average = True\n",
        "\n",
        "#create the model to train\n",
        "model = CNN(#TODO\n",
        "print('Total number of parameters: {}'.format(sum([p.numel() for p in model.parameters()])))\n",
        "\n",
        "trained_model_CNN = train_full(#TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyQUUPQwYt3y"
      },
      "source": [
        "Q10)  Complete the following function which visualizes the feature maps at each step of the model. Launch this viewer on a fully trained model.\n",
        "\n",
        "<font color='red'>Comment on the interpretability of the model. In particular, can we compare $x_1$ to $x_2$? And $x_2$ to $x_3$?</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UqLdFMbR6FD"
      },
      "source": [
        "def view_patch_false_color(feat_map, ax):\n",
        "  \"\"\"\n",
        "  visualize a feature_map in RGB space\n",
        "  \"\"\"\n",
        "  fmap_dim = feat_map.shape[1]\n",
        "  n_pix = feat_map.shape[2]\n",
        "  #we use a pca to project the embeddings to a RGB space\n",
        "  pca = PCA(n_components=3)\n",
        "  pca.fit(np.eye(fmap_dim))\n",
        "  #we need to adapt dimension and memory allocation to CPU\n",
        "  fmap_ = feat_map.cpu().detach().numpy().squeeze()\n",
        "  fmap_ = fmap_.reshape((fmap_dim, n_pix * n_pix)).transpose(1,0)\n",
        "  color = pca.transform(fmap_)\n",
        "  #we normalize for visibility\n",
        "  color = np.maximum(np.minimum(((color - color.mean(1, keepdims = True) +0.5) / (2 * color.std(1, keepdims = True))), 1), 0)\n",
        "  color = color.reshape((n_pix, n_pix,3), order= 'F')\n",
        "  ax.imshow(color)\n",
        "  plt.axis('off')\n",
        "\n",
        "def view_embeddings(model, patch_index = None, train = False):\n",
        "  \"\"\"\n",
        "  view the feature maps at all levels for a give model\n",
        "  \"\"\"\n",
        "  if patch_index is None:\n",
        "    patch_index = np.random.randint(n_train) if train \\\n",
        "    else np.random.randint(n_test)\n",
        "  patch, label = patch_loader(patch_index)\n",
        "\n",
        "  if model.is_cuda:\n",
        "    patch = patch.cuda()\n",
        "\n",
        "  #forms a batch of size 1  \n",
        "  input = patch[None,:,:,:]\n",
        "  with torch.no_grad(): #we do not need  to keep track of gradients here\n",
        "    x1 = #TODO\n",
        "    x2 = #TODO\n",
        "    x3 = #TODO\n",
        "    x4 = #TODO\n",
        "    x5 = #TODO\n",
        "    x6 = #TODO\n",
        "\n",
        "  fig = plt.figure(figsize=(25, 10)) #adapted dimension\n",
        "  ax = fig.add_subplot(1, 7, 1, aspect=1)\n",
        "  \n",
        "  ax.set(title='Input : %d x %d x %d \\n %s' %(input.shape[1],input.shape[2],input.shape[3], class_names[label]))\n",
        "  view_patch_RGB(patch.cpu(), ax)\n",
        "  ax = fig.add_subplot(1, 7, 2, aspect=1)\n",
        "  ax.set(title='x1 : %d x %d x %d' %(x1.shape[1:]))\n",
        "  view_patch_false_color(x1, ax)\n",
        "  ax = fig.add_subplot(1, 7, 3, aspect=1)\n",
        "  ax.set(title='x2 : %d x %d x %d' %(x2.shape[1:]))\n",
        "  view_patch_false_color(x2, ax)\n",
        "  ax = fig.add_subplot(1, 7, 4, aspect=1)\n",
        "  ax.set(title='x3 : %d x %d x %d' %(x3.shape[1:]))\n",
        "  view_patch_false_color(x3, ax)\n",
        "  ax = fig.add_subplot(1, 7, 5, aspect=1)\n",
        "  ax.set(title='x4 : %d x %d x %d' %(x4.shape[1:]))\n",
        "  view_patch_false_color(x4, ax)\n",
        "  ax = fig.add_subplot(1, 7, 6, aspect=1)\n",
        "  ax.set(title='x5 : %d x %d x %d' %(x5.shape[1:]))\n",
        "  view_patch_false_color(x5, ax)\n",
        "  ax = fig.add_subplot(1, 7, 7, aspect=1)\n",
        "  ax.set(title='x6 : %d' %(x6.shape[1:]))\n",
        "  view_patch_false_color(x6[:, :, None, None], ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6zw7UZZBEJF"
      },
      "source": [
        "for i in range(3):\n",
        "  view_embeddings(trained_model_CNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTfnooTsbKVc"
      },
      "source": [
        "$\\star$Q11 \n",
        "Study the effect of the batch size and learning rate. Try very small and large values, report the best configurations. In particular, interpret the observed relationship between batch size and learning rate, and propose an explanation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf8ejUDSGHVm"
      },
      "source": [
        "\n",
        "$\\star$Q12 Add a drop out layer on the previous to last layer of the classifier layer. Try different drop out rate, and comment on the effect, if any.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FSmdYKkGHbF"
      },
      "source": [
        "$\\star$Q13 The data set is imbalanced. We can weight the difference classes to  increase the importance of vegetation and buildings. Set the parameter `class_weight` of `CNN` to the tensor: \n",
        "`[5, 0.5, 1, 1, 1, 1, 0.5 , 1]`, and add it as a class weights option in the cross entropy loss (see pytorch doc) in `train` and `test`. Assess the effect oon the OA and the mIoU, and try other values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2f72QHJFqMe"
      },
      "source": [
        "$\\star$Q14 Change the width of the convolutions to try to find a better parametrization. What happens when the network gets too large (too many parameters)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-D14D0jFqKJ"
      },
      "source": [
        "$\\star$Q15 Implement adaptive learning rates using the `MultiStepLR` scheduler (look up the online torch documentation for usage). Implement a decay of $0.5$ and milestone at epochs $30$ and $40$ when training for $50$ epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRlM-qOezajb"
      },
      "source": [
        "$\\star$Q16 Implement a random forest baseline operating on the average vector. Compare its performance to the MLP and propose an explanation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0eErEUq1J3m"
      },
      "source": [
        "$\\star\\star$Q17 Study the effect of the quantity of training data by running the two models using only $50\\%$, $25\\%$, and $10\\%$ of the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQGf9dYRz2mF"
      },
      "source": [
        "$\\star\\star$Q18 Replace the average pooling in the CNN with a spatial maxpooling and comment on the effect. Implement a pooling operation which concatenate the spatial mean and deviation (std) over the parcel, and comment on the effect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MfNvnVwFqAp"
      },
      "source": [
        "$\\star\\star$Q19 Create the class `CNN3` which operates has a supplementary maxpool and two more convolutions before the spatial mean (the final layer before averageing is of size $\\lceil H/4\\rceil \\times \\lceil W/4 \\rceil \\times d$. Give the size of the receptive fields for both networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaAad8EKFsYZ"
      },
      "source": [
        "Q20 Open question: try to think of other ways to improve the model, and report your reasoning and results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de1iFEL8vsQL"
      },
      "source": [
        "**Data from**\n",
        "Garnot, V. S. F., Landrieu, L., Giordano, S., & Chehata, N. Satellite Image Time Series Classification with Pixel-Set Encoders and Temporal Self-Attention. In CVPR 2020.\n",
        "\n",
        "https://github.com/VSainteuf/pytorch-psetae"
      ]
    }
  ]
}